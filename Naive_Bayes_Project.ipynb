{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#for reading the dataset\n",
    "import os\n",
    "#for splitting the data\n",
    "from sklearn import model_selection\n",
    "#for plotting a graph between frequency and number of words\n",
    "import matplotlib.pyplot as plt\n",
    "#for sorting the dict by value in descending order\n",
    "import operator\n",
    "#to split the text into individual words\n",
    "import re\n",
    "#to use in-built sklearn Multinomial NB classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#to print classification report and confusion matrix\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop words not to be added in dictionary\n",
    "stop_words = [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"ain\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"aren\",\n",
    "              \"aren't\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\",\n",
    "              \"can\", \"couldn\", \"couldn't\", \"d\", \"did\", \"didn\", \"didn't\", \"do\", \"does\", \"doesn\", \"doesn't\", \"doing\", \"don\",\n",
    "              \"don't\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"hadn\", \"hadn't\", \"has\", \"hasn\",\n",
    "              \"hasn't\", \"have\", \"haven\", \"haven't\", \"having\", \"he\", \"her\", \"here\", \"hers\", \"herself\", \"him\", \"himself\",\n",
    "              \"his\", \"how\", \"i\", \"if\", \"in\", \"into\", \"is\", \"isn\", \"isn't\", \"it\", \"it's\", \"its\", \"itself\", \"just\", \"ll\",\n",
    "              \"m\", \"ma\", \"me\", \"mightn\", \"mightn't\", \"more\", \"most\", \"mustn\", \"mustn't\", \"my\", \"myself\", \"needn\", \"needn't\",\n",
    "              \"no\", \"nor\", \"not\", \"now\", \"o\", \"of\", \"off\", \"on\", \"once\", \"only\", \"or\", \"other\", \"our\", \"ours\", \"ourselves\",\n",
    "              \"out\", \"over\", \"own\", \"re\", \"s\", \"same\", \"shan\", \"shan't\", \"she\", \"she's\", \"should\", \"should've\", \"shouldn\",\n",
    "              \"shouldn't\", \"so\", \"some\", \"such\", \"t\", \"than\", \"that\", \"that'll\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\",\n",
    "              \"then\", \"there\", \"these\", \"they\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"ve\", \"very\",\n",
    "              \"was\", \"wasn\", \"wasn't\", \"we\", \"were\", \"weren\", \"weren't\", \"what\", \"when\", \"where\", \"which\", \"while\", \"who\",\n",
    "              \"whom\", \"why\", \"will\", \"with\", \"won\", \"won't\", \"wouldn\", \"wouldn't\", \"y\", \"you\", \"you'd\", \"you'll\", \"you're\",\n",
    "              \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"could\", \"he'd\", \"he'll\", \"he's\", \"here's\", \"how's\",\n",
    "              \"i'd\", \"i'll\", \"i'm\", \"i've\", \"let's\", \"ought\", \"she'd\", \"she'll\", \"that's\", \"there's\", \"they'd\", \"they'll\",\n",
    "              \"they're\", \"they've\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"what's\", \"when's\", \"where's\", \"who's\", \"why's\", \"would\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating list x and y where x has documents(texts) and y holds the class names for the classifier\n",
    "x = [] \n",
    "y = []\n",
    "#using os.listdir to iterate through the 20 classes in the dataset folder\n",
    "for folder in os.listdir(r\"C:\\Users\\daddy\\Desktop\\20_newsgroups\"):\n",
    "    #now iterating tthrough the documents in each class of dataset folder\n",
    "    for doc in os.listdir(r\"C:\\Users\\daddy\\Desktop\\20_newsgroups\\\\\" + folder):\n",
    "        #opening the documents in read-state and appending them to x and y having documents and class names respectively\n",
    "        with open(r\"C:\\Users\\daddy\\Desktop\\20_newsgroups\\\\\"+folder+'\\\\'+doc, \"r\") as doc_ds:\n",
    "            x.append((doc,doc_ds.read()))\n",
    "            y.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset int training and testing data\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x,y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the dictionary having count of all words\n",
    "count = {}\n",
    "#iterating over all rows of training dataset\n",
    "for i in range(len(x_train)):\n",
    "    #0th column holds a length 5 string and 1st columns hold the text of that document\n",
    "    text=x_train[i][1].lower()\n",
    "    #splitting the text into individual words using re.split function\n",
    "    words=re.split(r'\\W+',text)\n",
    "    #iterating over all individual words to create the count dict\n",
    "    for word in words:\n",
    "        #to skip the iteration if the word is an alphanumeric or a stop word or if length of word is less than or equal to 1\n",
    "        if not(word.isalpha()) or word in stop_words or len(word)<=1:\n",
    "            continue\n",
    "        #if word is ok, add it to dictionary and increase frequency if already added\n",
    "        if word in count:\n",
    "            count[word]+=1\n",
    "        else:\n",
    "            count[word]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the count dictionary in descending order by values\n",
    "sorted_count = sorted(count.items(), key=operator.itemgetter(1),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot graph between frequency and number of words\n",
    "df=sorted_count\n",
    "x_axis = []\n",
    "y_axis = []\n",
    "#iterating over the sorted dictionary\n",
    "for i in range(len(df)):\n",
    "    #plotting number of words on x-axis\n",
    "    x_axis.append(i)\n",
    "    #plotting frequency of those words in y-axis\n",
    "    y_axis.append(df[i][1])\n",
    "plt.plot(x_axis,y_axis)\n",
    "plt.title(\"Frequency vs Number of Words\")\n",
    "plt.xlabel(\"No. of words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.axis([0,8000,1,8000])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I chose top 2000 words to be in my feature set\n",
    "#iterating over top 2000 words in df which contains the sorted dictionary\n",
    "top_k_words=[df[i][0] for i in range(2000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get the dataset in terms of 2d array, we create an array of all 0 having dimensions \n",
    "#m*n, where m is number of rows, i.e. len of x_train and n is number of columns, i.e\n",
    "#length of top_k_words array as calculated above\n",
    "final_x_ds = np.zeros([len(x_train),len(top_k_words)],int)\n",
    "for i in range(len(x_train)):\n",
    "    #splitting the x_train into individual words\n",
    "    words = x_train[i][1].lower()\n",
    "    word = re.split(r'\\W+',words)\n",
    "    #Iterating over each word\n",
    "    for j in word:\n",
    "        #update frequency of that word (j) if it is present in our feature set\n",
    "        if j in top_k_words:\n",
    "            final_x_ds[i][top_k_words.index(j)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we are making the final x test dataset in terms of the required 2d array form\n",
    "final_x_test_ds = np.zeros([len(x_test),len(top_k_words)],int)\n",
    "for i in range(len(x_test)):\n",
    "    #splitting the x_test into individual words\n",
    "    words = x_test[i][1].lower()\n",
    "    word = re.split(r'\\W+',words)\n",
    "    #Iterating over each word\n",
    "    for j in word:\n",
    "        #update frequency of that word (j) if it is present in our feature set\n",
    "        if j in top_k_words:\n",
    "            final_x_test_ds[i][top_k_words.index(j)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x_train, y_train):\n",
    "    y_train=np.array(y_train)\n",
    "    #the final dictionary required\n",
    "    result = {}\n",
    "    #using the set function to get all unique class values\n",
    "    class_values = set(y_train)\n",
    "    #storing the total number of classes in our dictionary\n",
    "    result[\"total_data\"] = len(y_train)\n",
    "    #iterating over the several classes \n",
    "    for current_class in class_values:\n",
    "        #variable to store number of words in each class\n",
    "        total_word = 0\n",
    "        #making a dictionary for each class\n",
    "        result[current_class] = {}\n",
    "        #selecting those rows having class value as the current class\n",
    "        current_class_rows = (y_train == current_class)\n",
    "        x_train_current = final_x_ds[current_class_rows]\n",
    "        y_train_current = y_train[current_class_rows]\n",
    "        #iterating over our feature set\n",
    "        for word in top_k_words:\n",
    "            #selecting the ith column from the training dataset\n",
    "            word_i=(x_train_current[:,top_k_words.index(word)]).sum()\n",
    "            result[current_class][word]=word_i\n",
    "            #adding total number of words in a particular class in total_word variable\n",
    "            total_word+=word_i\n",
    "        result[current_class][\"current_class_words\"]=total_word\n",
    "        #number of rows having class name as current class\n",
    "        result[current_class][\"total_count\"] = len(y_train_current)\n",
    "    #returning the result dictionary\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(dictionary,x,current_class):\n",
    "    #first, I calculate the probability P(y = current_class)\n",
    "    output = np.log(dictionary[current_class][\"total_count\"]) - np.log(dictionary[\"total_data\"])\n",
    "    #listing all keys of dictionary\n",
    "    feature=list(dictionary[current_class].keys())\n",
    "    #removing current_class_words and total_count features while iteration \n",
    "    for j in range (len(feature)-2):\n",
    "        xj=x[j]\n",
    "        #If the frequency of that word is 0, then we ignore it\n",
    "        if xj==0:\n",
    "            current_prob=0\n",
    "        else:\n",
    "            #calculating the probability after applying laplace correction\n",
    "            n=dictionary[current_class][feature[j]]+1\n",
    "            d=dictionary[current_class][\"current_class_words\"]+len(dictionary[current_class].keys())-2\n",
    "            current_prob=np.log(n)-np.log(d)\n",
    "        output+=current_prob\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterating over all classes of our dictionary\n",
    "#and calculating probability\n",
    "#returning the prediction in form of the best class\n",
    "#depending on the probability calculated using the\n",
    "#probability function\n",
    "def PredictSinglePoint(dictionary, x):\n",
    "    first_run=True\n",
    "    best_prob = -1000\n",
    "    classes=dictionary.keys()\n",
    "    for i in classes:\n",
    "        if i==\"total_data\":\n",
    "            continue\n",
    "        prob=probability(dictionary,x,i)\n",
    "        if first_run or prob>best_prob:\n",
    "            best_prob=prob\n",
    "            best_class=i\n",
    "        first_run=False\n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to calculate the predictions, I created a list\n",
    "#and appending point-wise probability and best-class in the y_pred list\n",
    "def predict(x_test,dictionary):\n",
    "    y_pred=[]\n",
    "    for x in x_test:\n",
    "        y_pred.append(PredictSinglePoint(dictionary, x))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the score of our Multinomial NB classifier\n",
    "#which is calculated using mean-accuracy method\n",
    "#if prediction is correct, we increase count by 1\n",
    "#and the calculate the mean\n",
    "def score(y_test,y_pred):\n",
    "        count = 0\n",
    "        for i in range(len(y_pred)):\n",
    "            if y_pred[i] == y_test[i]:\n",
    "                count+=1\n",
    "        return count/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the y_predictions using the predict function\n",
    "#and making the final dictionary using the fit function\n",
    "dictionary=fit(final_x_ds,y_train)\n",
    "y_pred=predict(final_x_test_ds, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on testing_data: 0.8448\n",
      "[[201   1   0   0   0   0   1   1   2   2   0   0   1   3   0   0   0   0\n",
      "    0  21]\n",
      " [  0 214   0  19   5   3   4   0   0   1   0   0   3   2   2   0   0   0\n",
      "    0   0]\n",
      " [  0  38   3 127   8  53   3   0   0   0   0   3  10   0   1   0   1   0\n",
      "    2   0]\n",
      " [  0   1   0 223  11   0   5   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   2   0  18 210   0   6   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0  23   1  10   9 191   1   0   1   0   0   1   2   1   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   9   1   0 235   8   0   0   0   0   6   1   1   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   1   1  10 247   5   0   0   0   5   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   2   1 279   0   0   0   0   0   0   0   1   0\n",
      "    1   0]\n",
      " [  0   0   0   0   0   0   3   0   0 237   8   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   1   1   0   5 224   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   2   0   0   0   1   0   0   0   0   0 227   3   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   3   0   3   1   0   5   1   0   0   0   0 230   1   0   0   0   0\n",
      "    0   0]\n",
      " [  0   8   0   0   2   1   1   1   3   0   1   1   4 233   1   0   0   0\n",
      "    0   0]\n",
      " [  0   5   0   0   0   0   1   0   1   0   0   0   3   3 229   0   0   0\n",
      "    4   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 252   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   2   0   0   2   0   0   0   0 227   0\n",
      "   14   4]\n",
      " [  0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   7 256\n",
      "   17   0]\n",
      " [  0   0   0   0   0   0   2   0   0   1   0   1   0   2   3   0  42  14\n",
      "  183  11]\n",
      " [ 57   1   0   0   0   0   1   0   1   0   0   1   0   0   0   7  16   2\n",
      "   27 123]]\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.78      0.86      0.82       233\n",
      "           comp.graphics       0.72      0.85      0.78       253\n",
      " comp.os.ms-windows.misc       0.75      0.01      0.02       249\n",
      "comp.sys.ibm.pc.hardware       0.55      0.93      0.69       240\n",
      "   comp.sys.mac.hardware       0.85      0.89      0.87       236\n",
      "          comp.windows.x       0.76      0.80      0.78       240\n",
      "            misc.forsale       0.84      0.90      0.87       261\n",
      "               rec.autos       0.95      0.92      0.93       269\n",
      "         rec.motorcycles       0.95      0.98      0.97       284\n",
      "      rec.sport.baseball       0.96      0.96      0.96       248\n",
      "        rec.sport.hockey       0.96      0.97      0.97       231\n",
      "               sci.crypt       0.96      0.97      0.97       233\n",
      "         sci.electronics       0.86      0.94      0.90       244\n",
      "                 sci.med       0.95      0.91      0.93       256\n",
      "               sci.space       0.97      0.93      0.95       246\n",
      "  soc.religion.christian       0.97      1.00      0.99       252\n",
      "      talk.politics.guns       0.77      0.91      0.84       249\n",
      "   talk.politics.mideast       0.94      0.91      0.93       281\n",
      "      talk.politics.misc       0.74      0.71      0.72       259\n",
      "      talk.religion.misc       0.77      0.52      0.62       236\n",
      "\n",
      "                accuracy                           0.84      5000\n",
      "               macro avg       0.85      0.84      0.82      5000\n",
      "            weighted avg       0.85      0.84      0.83      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#checking the score( mean accuracy) using the score function\n",
    "#and then printing out the confusion_matrix and classification_report\n",
    "print(\"Score on testing_data:\",score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training data: 0.8599719943988797\n",
      "Score on testing data: 0.8192\n",
      "[[188   0   0   0   0   0   1   4   3   0   2   0   0   2   0   1   0   0\n",
      "    0  32]\n",
      " [  1 201   0  16   7  14   3   2   0   0   0   0   5   3   1   0   0   0\n",
      "    0   0]\n",
      " [  0  36  18 116  10  54   7   1   0   0   0   1   5   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0 210  21   0   5   0   0   0   0   0   3   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   2   0  24 203   0   7   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0  22   1  17  12 175   2   0   2   1   0   1   4   1   2   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   6   4   0 237   6   1   0   1   0   5   0   0   0   1   0\n",
      "    0   0]\n",
      " [  0   0   0   0   1   0  10 240   7   1   2   0   7   0   0   0   1   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   2   6 274   2   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   4   4   2 224  13   0   0   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   3   7 220   0   0   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   3   0   0   0   2   1   0   0   0   0 222   5   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   4   0   8   4   0   5   9   1   0   1   0 207   2   2   0   0   0\n",
      "    1   0]\n",
      " [  0   5   0   1   6   2   2   5   8   2   0   1   3 216   4   0   0   1\n",
      "    0   0]\n",
      " [  1   2   0   1   1   0   1   3   2   2   2   0   5   2 222   0   1   0\n",
      "    1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 252   0   0\n",
      "    0   0]\n",
      " [  0   0   0   1   0   0   0   0   3   0   0   3   0   0   0   0 225   0\n",
      "   12   5]\n",
      " [  0   0   0   0   1   0   4   3   1   1   1   0   1   0   0   0   8 239\n",
      "   21   1]\n",
      " [  0   0   0   0   0   0   1   0   0   2   0   3   0   2   2   1  34  14\n",
      "  180  20]\n",
      " [ 44   1   0   0   0   0   0   0   1   0   1   0   0   1   0   8  14   2\n",
      "   21 143]]\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.80      0.81      0.81       233\n",
      "           comp.graphics       0.73      0.79      0.76       253\n",
      " comp.os.ms-windows.misc       0.95      0.07      0.13       249\n",
      "comp.sys.ibm.pc.hardware       0.53      0.88      0.66       240\n",
      "   comp.sys.mac.hardware       0.75      0.86      0.80       236\n",
      "          comp.windows.x       0.71      0.73      0.72       240\n",
      "            misc.forsale       0.81      0.91      0.86       261\n",
      "               rec.autos       0.85      0.89      0.87       269\n",
      "         rec.motorcycles       0.89      0.96      0.93       284\n",
      "      rec.sport.baseball       0.93      0.90      0.91       248\n",
      "        rec.sport.hockey       0.91      0.95      0.93       231\n",
      "               sci.crypt       0.96      0.95      0.96       233\n",
      "         sci.electronics       0.83      0.85      0.84       244\n",
      "                 sci.med       0.94      0.84      0.89       256\n",
      "               sci.space       0.94      0.90      0.92       246\n",
      "  soc.religion.christian       0.96      1.00      0.98       252\n",
      "      talk.politics.guns       0.79      0.90      0.84       249\n",
      "   talk.politics.mideast       0.93      0.85      0.89       281\n",
      "      talk.politics.misc       0.76      0.69      0.73       259\n",
      "      talk.religion.misc       0.71      0.61      0.65       236\n",
      "\n",
      "                accuracy                           0.82      5000\n",
      "               macro avg       0.83      0.82      0.80      5000\n",
      "            weighted avg       0.84      0.82      0.81      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#USING THE IN-BUILT SK-LEARN CLASSIFIER FOR MULTINOMIAL NAIVE-BAYES\n",
    "clf=MultinomialNB()\n",
    "clf.fit(final_x_ds,y_train)\n",
    "y_pred=clf.predict(final_x_test_ds)\n",
    "print(\"Score on training data:\",clf.score(final_x_ds,y_train))\n",
    "print(\"Score on testing data:\",clf.score(final_x_test_ds,y_test))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMPARISON B/W In-Built MultinomialNB classifier and Self-Implementation Of Multinomial NB classifer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Score on testing data by Self-Implemented NB Classifier = 0.8448\n",
    "#Score on testing data by In-built SKLearn NB classifier = 0.8192\n",
    "\n",
    "#this shows that even though there's quite difference in the score obtained by both methods\n",
    "#but in my case, the self-implemented Multinomial NB classifier achieves better score on \n",
    "#testing data than in-built sklearn Multinomial NB classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
